services:
  # Backend API Service
  - type: web
    name: hoistscout-api
    runtime: docker
    repo: https://github.com/jakelindsay87/hoistscout
    dockerfilePath: backend/Dockerfile
    envVars:
      - key: DATABASE_URL
        fromDatabase:
          name: hoistscout-db
          property: connectionString
      - key: REDIS_URL
        value: redis://red-d1hljoruibrs73fe7vkg:6379
      - key: SECRET_KEY
        generateValue: true
      - key: ENVIRONMENT
        value: production
      - key: PYTHONUNBUFFERED
        value: "1"
      - key: PYTHONPATH
        value: "/app"
      - key: OLLAMA_BASE_URL
        value: https://hoistscout-ollama.onrender.com
      - key: OLLAMA_MODEL
        value: llama3.2
      - key: USE_GEMINI
        value: "true"
      - key: GEMINI_API_KEY
        generateValue: true  # You'll need to update this with your actual API key
      - key: GEMINI_MODEL
        value: gemini-1.5-flash
    healthCheckPath: /api/health
    autoDeploy: true
    plan: starter

  # Frontend Service
  - type: web
    name: hoistscout-frontend
    runtime: docker
    repo: https://github.com/jakelindsay87/hoistscout
    dockerfilePath: frontend/Dockerfile
    buildCommand: docker build --build-arg NEXT_PUBLIC_API_URL=https://hoistscout-api.onrender.com -f frontend/Dockerfile .
    envVars:
      - key: NEXT_PUBLIC_API_URL
        value: https://hoistscout-api.onrender.com
      - key: NODE_ENV
        value: production
      - key: NEXT_TELEMETRY_DISABLED
        value: "1"
      - key: NODE_OPTIONS
        value: "--max-old-space-size=512"
    autoDeploy: true
    plan: starter

  # Worker Service for background tasks
  - type: worker
    name: hoistscout-worker
    runtime: docker
    repo: https://github.com/jakelindsay87/hoistscout
    dockerfilePath: backend/Dockerfile
    dockerCommand: celery -A app.worker worker --loglevel=info
    envVars:
      - key: DATABASE_URL
        fromDatabase:
          name: hoistscout-db
          property: connectionString
      - key: REDIS_URL
        value: redis://red-d1hljoruibrs73fe7vkg:6379
      - key: PYTHONUNBUFFERED
        value: "1"
      - key: PYTHONPATH
        value: "/app"
      - key: OLLAMA_BASE_URL
        value: https://hoistscout-ollama.onrender.com
      - key: OLLAMA_MODEL
        value: llama3.2
      - key: USE_GEMINI
        value: "true"
      - key: GEMINI_API_KEY
        generateValue: true  # You'll need to update this with your actual API key
      - key: GEMINI_MODEL
        value: gemini-1.5-flash
    autoDeploy: true
    plan: starter

  # Ollama Proxy Service
  - type: web
    name: hoistscout-ollama
    runtime: docker
    repo: https://github.com/jakelindsay87/hoistscout
    dockerfilePath: ollama-proxy/Dockerfile
    envVars:
      - key: MOCK_MODE
        value: "true"
      - key: PYTHONUNBUFFERED
        value: "1"
    healthCheckPath: /health
    autoDeploy: true
    plan: starter

# Database
databases:
  - name: hoistscout-db
    databaseName: hoistscout
    user: hoistscout_user
    plan: free
    postgresMajorVersion: 16