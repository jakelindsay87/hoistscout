# Worker Dockerfile for RQ background jobs with Playwright
FROM python:3.11-slim

# Set environment variables
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1
ENV PIP_NO_CACHE_DIR=1
ENV PIP_DISABLE_PIP_VERSION_CHECK=1

# Install system dependencies
RUN apt-get update && apt-get install -y \
    curl \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Install Poetry
RUN pip install poetry==1.8.3

# Configure Poetry
ENV POETRY_NO_INTERACTION=1
ENV POETRY_VIRTUALENVS_IN_PROJECT=1
ENV POETRY_CACHE_DIR=/tmp/poetry_cache

# Set work directory
WORKDIR /app

# Copy Poetry files
COPY pyproject.toml ./

# Install dependencies including AI extra (will generate lock file)
RUN poetry lock && poetry install --only main -E ai && rm -rf $POETRY_CACHE_DIR

# Activate virtual environment and install Playwright browsers
RUN . /app/.venv/bin/activate && pip install playwright && playwright install chromium --with-deps

# Make sure to use venv
ENV PATH="/app/.venv/bin:$PATH"

# Copy source code
COPY . .

# Create data directory for scraping results
RUN mkdir -p /app/data

# Health check - check if worker process is running
HEALTHCHECK --interval=30s --timeout=30s --start-period=60s --retries=5 \
    CMD pgrep -f "rq worker" || exit 1

# Run the RQ worker with improved startup script
CMD ["poetry", "run", "python", "-m", "hoistscraper.worker_startup"]