# HoistScout - Enterprise Tender Scraping Platform

HoistScout is a bulletproof web scraping platform that extracts tender and grant opportunities from 1000+ websites while processing 5M+ PDF documents with zero manual intervention.

## üöÄ Key Features

- **Intelligent Extraction**: LLM-powered adaptive scraping with ScrapeGraphAI
- **Enterprise Scale**: Handle 5M+ documents with MinIO storage
- **Zero Manual Work**: Self-healing scrapers that adapt to site changes
- **Production Grade**: Anti-detection, CAPTCHA solving, proxy rotation
- **Real-time Updates**: WebSocket integration for live job monitoring
- **Secure**: Encrypted credentials, RBAC, comprehensive audit logging

## üèóÔ∏è Architecture

### Core Technologies

- **Scraping Engine**: ScrapeGraphAI with Ollama LLM
- **Anti-Detection**: FlareSolverr, 2captcha, undetected-chromedriver
- **Document Processing**: Unstructured for PDF/document extraction
- **Backend**: FastAPI with async SQLAlchemy
- **Task Queue**: Celery with Redis
- **Storage**: PostgreSQL (data) + MinIO (documents)
- **Frontend**: Next.js 14 with TypeScript
- **Monitoring**: Prometheus + Grafana

## üìä Performance

- Process 5,000 PDFs per hour
- Handle 1,000 concurrent scraping sessions
- Search 5M+ opportunities in <100ms
- API response times <500ms
- 99.9% uptime with auto-recovery

## üöÄ Quick Start

### Prerequisites
- Python 3.11+
- Docker & Docker Compose
- 16GB+ RAM recommended
- 100GB+ storage for documents

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/hoistscout.git
cd hoistscout

# Start infrastructure services
docker-compose up -d postgres redis minio

# Install Python dependencies
pip install poetry
poetry install

# Setup database
poetry run alembic upgrade head

# Start the backend
poetry run uvicorn app.main:app --reload

# In another terminal, start Celery workers
poetry run celery -A app.worker worker --loglevel=info

# In another terminal, start the frontend
cd frontend && npm install && npm run dev
```

### First Run

1. Access the web interface at http://localhost:3000
2. Create an admin account
3. Add your first website to scrape
4. Watch as HoistScout automatically learns and extracts tenders!

## üìÅ Project Structure

```
hoistscout/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/          # FastAPI endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ core/         # Scraping engine
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/       # Database models
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ worker.py     # Celery tasks
‚îÇ   ‚îî‚îÄ‚îÄ tests/
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ app/              # Next.js app router
‚îÇ   ‚îú‚îÄ‚îÄ components/       # React components
‚îÇ   ‚îî‚îÄ‚îÄ lib/              # Utilities
‚îú‚îÄ‚îÄ docker-compose.yml    # Local development
‚îî‚îÄ‚îÄ docs/                 # Documentation
```

## üîí Security

- Encrypted credential storage
- JWT authentication with refresh tokens
- Role-based access control
- Comprehensive audit logging
- Input validation and sanitization

## üìö Documentation

See the [full PRD](docs/PRD.md) for detailed technical specifications.

## ü§ù Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

## üìÑ License

MIT License - see [LICENSE](LICENSE) for details.